import asyncio

from pydantic_ai import AgentRunResultEvent
from run_stream_event_stream_handler import handle_event, output_messages, weather_agent


async def main():
    user_prompt = "What will the weather be like in Paris on 2025/10/12?"

    async for event in weather_agent.run_stream_events(user_prompt):
        if isinstance(event, AgentRunResultEvent):
            output_messages.append(f"[Final Output] {event.result.output}")
        else:
            await handle_event(event)


if __name__ == "__main__":
    asyncio.run(main())

    print(output_messages)
    """
    [
        "[Request] Starting part 0: ToolCallPart(tool_name='weather_forecast', tool_call_id='0001')",
        '[Request] Part 0 args delta: {"location":"Pa',
        '[Request] Part 0 args delta: ris","forecast_',
        '[Request] Part 0 args delta: date":"2030-01-',
        '[Request] Part 0 args delta: 01"}',
        (
            '[Tools] The LLM calls tool=\'weather_forecast\' with '
            'args={"location":"Paris","forecast_date":"2030-01-01"} (tool_call_id=\'0001\')'
        ),
        "[Tools] Tool call '0001' returned => The forecast in Paris on 2030-01-01 is 24Â°C and sunny.",
        "[Request] Starting part 0: TextPart(content='It will be ')",
        '[Result] The model starting producing a final result (tool_name=None)',
        "[Request] Part 0 text delta: 'warm and sunny '",
        "[Request] Part 0 text delta: 'in Paris on '",
        "[Request] Part 0 text delta: 'Tuesday.'",
        '[Final Output] It will be warm and sunny in Paris on Tuesday.',
    ]
    """
